{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "191fc804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.CLIP import CLIP, text_encoder\n",
    "import torch\n",
    "from src.io import Image_Text_Dataset\n",
    "from src.Trainer import train_clip\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1af20119",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c443ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manth145/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 28123/28123 [00:10<00:00, 2740.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28123 images with no NaNs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "illustris_tng_100_dataset1 = Image_Text_Dataset(fits_file='/d1/manth145/UVCANDELS/synthetic_images/hlsp_illustris_hst_acs_tng100-7-6-yxz_f814w_v1_sim.fits', cutout_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59a6896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split = 0.9\n",
    "batch_size = 32\n",
    "nworkers = 6\n",
    "\n",
    "dataloader = DataLoader(illustris_tng_100_dataset1, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=nworkers, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec2eeead",
   "metadata": {},
   "outputs": [],
   "source": [
    "something, condition = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a580ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt_encoder = text_encoder(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60ad81f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt_encoder(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51a73677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manth145/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/manth145/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "Epoch 0\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:30<00:00, 29.06it/s, Loss: 3.1807, Scale: 10.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed. Average Loss: 3.1807\n",
      "Saved Model ./checkpoints//clip_checkpoint_epoch_0.pt\n",
      "Epoch 1\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████████| 879/879 [00:28<00:00, 30.89it/s, Loss: 2.5845, Scale: 9.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed. Average Loss: 2.5845\n",
      "Epoch 2\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 30.20it/s, Loss: 2.3299, Scale: 9.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed. Average Loss: 2.3299\n",
      "Epoch 3\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 30.06it/s, Loss: 2.1280, Scale: 9.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 completed. Average Loss: 2.1280\n",
      "Epoch 4\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 30.03it/s, Loss: 2.0205, Scale: 9.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 completed. Average Loss: 2.0205\n",
      "Epoch 5\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 29.87it/s, Loss: 1.9193, Scale: 9.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 completed. Average Loss: 1.9193\n",
      "Saved Model ./checkpoints//clip_checkpoint_epoch_5.pt\n",
      "Epoch 6\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████████| 879/879 [00:28<00:00, 30.32it/s, Loss: 1.8715, Scale: 9.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 completed. Average Loss: 1.8715\n",
      "Epoch 7\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 29.51it/s, Loss: 1.8694, Scale: 9.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 completed. Average Loss: 1.8694\n",
      "Epoch 8\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 29.76it/s, Loss: 1.8626, Scale: 9.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 completed. Average Loss: 1.8626\n",
      "Epoch 9\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 29.43it/s, Loss: 1.8279, Scale: 9.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 completed. Average Loss: 1.8279\n",
      "Epoch 10\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:30<00:00, 29.00it/s, Loss: 1.7445, Scale: 10.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 completed. Average Loss: 1.7445\n",
      "Saved Model ./checkpoints//clip_checkpoint_epoch_10.pt\n",
      "Epoch 11\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 30.03it/s, Loss: 1.6332, Scale: 10.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 completed. Average Loss: 1.6332\n",
      "Epoch 12\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:30<00:00, 28.48it/s, Loss: 1.5222, Scale: 10.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 completed. Average Loss: 1.5222\n",
      "Epoch 13\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 29.45it/s, Loss: 1.4070, Scale: 10.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 completed. Average Loss: 1.4070\n",
      "Epoch 14\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 30.20it/s, Loss: 1.2823, Scale: 10.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 completed. Average Loss: 1.2823\n",
      "Epoch 15\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 30.16it/s, Loss: 1.1640, Scale: 10.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 completed. Average Loss: 1.1640\n",
      "Saved Model ./checkpoints//clip_checkpoint_epoch_15.pt\n",
      "Epoch 16\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:28<00:00, 30.58it/s, Loss: 1.0615, Scale: 11.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 completed. Average Loss: 1.0615\n",
      "Epoch 17\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 30.27it/s, Loss: 0.9838, Scale: 11.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 completed. Average Loss: 0.9838\n",
      "Epoch 18\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:28<00:00, 30.62it/s, Loss: 0.8944, Scale: 11.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 completed. Average Loss: 0.8944\n",
      "Epoch 19\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 29.99it/s, Loss: 0.8109, Scale: 11.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 completed. Average Loss: 0.8109\n",
      "Epoch 20\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 29.66it/s, Loss: 0.7494, Scale: 12.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 completed. Average Loss: 0.7494\n",
      "Saved Model ./checkpoints//clip_checkpoint_epoch_20.pt\n",
      "Epoch 21\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 29.83it/s, Loss: 0.6962, Scale: 12.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 completed. Average Loss: 0.6962\n",
      "Epoch 22\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 30.21it/s, Loss: 0.6495, Scale: 13.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 completed. Average Loss: 0.6495\n",
      "Epoch 23\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 29.64it/s, Loss: 0.5996, Scale: 13.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 completed. Average Loss: 0.5996\n",
      "Epoch 24\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 29.76it/s, Loss: 0.5555, Scale: 13.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 completed. Average Loss: 0.5555\n",
      "Epoch 25\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 29.68it/s, Loss: 0.5333, Scale: 14.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 completed. Average Loss: 0.5333\n",
      "Saved Model ./checkpoints//clip_checkpoint_epoch_25.pt\n",
      "Epoch 26\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 30.17it/s, Loss: 0.4978, Scale: 14.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 completed. Average Loss: 0.4978\n",
      "Epoch 27\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 29.92it/s, Loss: 0.4678, Scale: 15.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 completed. Average Loss: 0.4678\n",
      "Epoch 28\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 29.53it/s, Loss: 0.4517, Scale: 15.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 completed. Average Loss: 0.4517\n",
      "Epoch 29\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 29.94it/s, Loss: 0.4282, Scale: 15.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 completed. Average Loss: 0.4282\n",
      "Epoch 30\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 30.08it/s, Loss: 0.4060, Scale: 16.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 completed. Average Loss: 0.4060\n",
      "Saved Model ./checkpoints//clip_checkpoint_epoch_30.pt\n",
      "Epoch 31\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:30<00:00, 28.78it/s, Loss: 0.3777, Scale: 16.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 completed. Average Loss: 0.3777\n",
      "Epoch 32\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 30.15it/s, Loss: 0.3704, Scale: 16.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 completed. Average Loss: 0.3704\n",
      "Epoch 33\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 29.72it/s, Loss: 0.3576, Scale: 17.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 completed. Average Loss: 0.3576\n",
      "Epoch 34\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 30.05it/s, Loss: 0.3408, Scale: 17.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 completed. Average Loss: 0.3408\n",
      "Epoch 35\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 29.88it/s, Loss: 0.3258, Scale: 17.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 completed. Average Loss: 0.3258\n",
      "Saved Model ./checkpoints//clip_checkpoint_epoch_35.pt\n",
      "Epoch 36\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 29.32it/s, Loss: 0.3157, Scale: 18.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 completed. Average Loss: 0.3157\n",
      "Epoch 37\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 29.88it/s, Loss: 0.3097, Scale: 18.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 completed. Average Loss: 0.3097\n",
      "Epoch 38\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 29.40it/s, Loss: 0.2988, Scale: 18.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 completed. Average Loss: 0.2988\n",
      "Epoch 39\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 30.15it/s, Loss: 0.2912, Scale: 18.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 completed. Average Loss: 0.2912\n",
      "Epoch 40\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:28<00:00, 30.77it/s, Loss: 0.2808, Scale: 19.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 completed. Average Loss: 0.2808\n",
      "Saved Model ./checkpoints//clip_checkpoint_epoch_40.pt\n",
      "Epoch 41\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:28<00:00, 30.74it/s, Loss: 0.2675, Scale: 19.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 completed. Average Loss: 0.2675\n",
      "Epoch 42\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:28<00:00, 30.37it/s, Loss: 0.2592, Scale: 19.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 completed. Average Loss: 0.2592\n",
      "Epoch 43\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:28<00:00, 30.82it/s, Loss: 0.2517, Scale: 19.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 completed. Average Loss: 0.2517\n",
      "Epoch 44\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:28<00:00, 30.54it/s, Loss: 0.2493, Scale: 20.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 completed. Average Loss: 0.2493\n",
      "Epoch 45\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:28<00:00, 30.39it/s, Loss: 0.2420, Scale: 20.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 completed. Average Loss: 0.2420\n",
      "Saved Model ./checkpoints//clip_checkpoint_epoch_45.pt\n",
      "Epoch 46\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 29.82it/s, Loss: 0.2367, Scale: 20.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 completed. Average Loss: 0.2367\n",
      "Epoch 47\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:28<00:00, 30.64it/s, Loss: 0.2296, Scale: 20.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 completed. Average Loss: 0.2296\n",
      "Epoch 48\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 30.00it/s, Loss: 0.2263, Scale: 20.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 completed. Average Loss: 0.2263\n",
      "Epoch 49\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 879/879 [00:29<00:00, 29.54it/s, Loss: 0.2236, Scale: 21.0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 completed. Average Loss: 0.2236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = CLIP(embed_dim=128, temperature=0.1, vocab_size=50000)\n",
    "\n",
    "trained_model = train_clip(model=model, device=device, train_loader = dataloader, \n",
    "                           learning_rate=1e-4, dest_folder='./checkpoints')\n",
    "\n",
    "# #save the trained model\n",
    "# torch.save(trained_model.state_dict(), 'clip_trained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import CLIPTokenizer as HFCLIPTokenizer\n",
    "# tokenizer = HFCLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\", force_download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6089f444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer(\"(P1:1.56), (P2:10.6)\", padding=\"max_length\", max_length = 64, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb4be012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [49406, 263, 335, 272, 281, 272, 13, 2361, 263, 335, 273, 281, 280, 269, 277, 264, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer(\"(P1:1.), (P2:9.6)\", padding=\"max_length\", max_length = 64, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bded43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(something[0,1,:,:].cpu().numpy(), cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba04ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_folder = './checkpoints/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2775c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest_folder.endswith('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31831ab4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'condition' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_756305/2525313574.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcondition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'condition' is not defined"
     ]
    }
   ],
   "source": [
    "condition.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2982966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 20, 21, 21, 21,\n",
       "        21, 21, 21, 21, 21, 20, 21, 21, 21, 20, 21, 22, 21, 20])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "985e35e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(condition, dim=1, index=condition.argmax(dim=-1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b83c05f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
       "        49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
       "        49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
       "        49407, 49407], dtype=torch.int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition[torch.arange(32), condition.argmax(dim=-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31dc89d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_random_tensor = torch.rand(32, 64, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a33a7b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 128])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d01168c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32, 128])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(some_random_tensor, dim=1, index=condition.argmax(dim=-1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c43fd0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32, 128])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(some_random_tensor, dim=1, index=condition.argmax(dim=-1))[torch.arange(32)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70ed68ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_random_tensor[torch.arange(32), (21*torch.ones(32)).to(torch.int32)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9612d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 20, 20, 21, 21, 21, 22, 20, 21, 21, 21, 21, 20, 21,\n",
      "        21, 21, 20, 22, 18, 20, 21, 21, 21, 21, 21, 21, 21, 20])\n",
      "torch.Size([32, 64]) tensor([20, 20, 21, 21, 21, 21, 21, 20, 21, 21, 19, 22, 21, 20, 21, 21, 21, 19,\n",
      "        21, 20, 20, 21, 21, 21, 21, 22, 21, 21, 21, 21, 21, 20])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 22, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
      "        21, 21, 21, 20, 21, 21, 21, 21, 21, 20, 19, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 21, 21, 21, 22, 20, 21, 21, 21, 21, 22, 22, 21, 21,\n",
      "        21, 21, 19, 22, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 19, 20, 21, 21, 21, 21, 21, 21,\n",
      "        21, 21, 21, 21, 20, 21, 21, 21, 20, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 20, 22, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 22,\n",
      "        21, 21, 19, 19, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([20, 21, 20, 21, 21, 21, 21, 20, 19, 21, 20, 21, 21, 21, 20, 21, 20, 21,\n",
      "        22, 21, 21, 21, 21, 21, 21, 22, 21, 19, 20, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 20, 21, 21, 21, 20, 20, 21, 21, 20, 20, 20, 21, 21, 21,\n",
      "        21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 19, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21,\n",
      "        21, 20, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 19, 20])\n",
      "torch.Size([32, 64]) tensor([20, 21, 21, 21, 21, 21, 20, 18, 21, 21, 21, 20, 21, 21, 21, 21, 22, 21,\n",
      "        19, 21, 21, 20, 21, 21, 21, 20, 20, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([20, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 22, 20, 21, 21, 20, 21,\n",
      "        21, 21, 19, 20, 21, 21, 21, 19, 21, 21, 21, 21, 20, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 20, 21, 21, 21, 20, 22, 21, 21, 21, 21, 21, 21, 21,\n",
      "        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([20, 19, 20, 21, 21, 20, 21, 21, 21, 21, 20, 21, 20, 21, 21, 21, 21, 21,\n",
      "        21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20,\n",
      "        21, 20, 21, 21, 21, 22, 21, 20, 21, 21, 22, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 20, 21, 21, 21, 22, 21, 21, 21, 20, 21, 21, 21, 20, 21, 21,\n",
      "        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 22, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 22,\n",
      "        21, 21, 21, 21, 21, 20, 20, 21, 21, 20, 21, 21, 21, 22])\n",
      "torch.Size([32, 64]) tensor([21, 21, 22, 21, 21, 21, 20, 21, 20, 21, 21, 21, 21, 19, 20, 20, 21, 21,\n",
      "        21, 21, 21, 20, 21, 21, 21, 21, 20, 21, 18, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 20, 21, 22, 21, 21, 22, 21, 21, 21, 20, 21, 21, 21, 21, 21, 18, 21,\n",
      "        19, 21, 21, 20, 21, 20, 21, 21, 21, 21, 21, 21, 22, 21])\n",
      "torch.Size([32, 64]) tensor([22, 21, 21, 21, 21, 21, 21, 21, 21, 20, 20, 21, 20, 21, 21, 21, 21, 21,\n",
      "        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 19, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 22, 21, 21, 22, 21, 21, 21, 20, 22, 21, 21, 21, 21, 21,\n",
      "        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 20, 22, 21])\n",
      "torch.Size([32, 64]) tensor([21, 20, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 20, 21, 21, 21, 20, 21,\n",
      "        21, 21, 21, 21, 21, 21, 19, 20, 21, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 21, 19, 21, 21, 21, 21, 22, 21, 22, 21, 18, 21, 21,\n",
      "        21, 19, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 19, 21, 21, 21, 21,\n",
      "        21, 20, 21, 21, 20, 21, 21, 21, 21, 21, 20, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21,\n",
      "        21, 21, 20, 19, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 22, 21, 21, 21, 20, 21, 19, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21,\n",
      "        21, 20, 20, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 19, 22, 20, 21, 21, 21, 21,\n",
      "        21, 21, 21, 22, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([19, 21, 22, 21, 21, 20, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
      "        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 22, 20, 20, 19, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21,\n",
      "        21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 22, 21, 20, 21])\n",
      "torch.Size([32, 64]) tensor([21, 20, 17, 22, 21, 21, 21, 22, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21,\n",
      "        21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 20, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 20, 19, 21, 21, 21, 21, 21, 20, 21, 21, 21, 19, 21, 21,\n",
      "        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 20, 20, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 20, 21,\n",
      "        21, 22, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 20, 21, 21, 20, 21, 21, 20, 21, 20, 20, 21, 21, 21, 21, 22, 21,\n",
      "        20, 21, 21, 20, 21, 21, 20, 21, 20, 21, 21, 21, 22, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 19, 21, 21, 21, 20, 20, 19,\n",
      "        19, 21, 21, 21, 21, 21, 22, 21, 19, 21, 21, 20, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 21, 21, 22, 21, 21, 21, 21, 22, 20, 21, 20, 21, 21,\n",
      "        21, 21, 21, 20, 21, 20, 21, 21, 21, 21, 21, 21, 20, 21])\n",
      "torch.Size([32, 64]) tensor([20, 21, 21, 21, 20, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21,\n",
      "        21, 21, 21, 22, 21, 21, 21, 22, 21, 20, 22, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 19, 21, 21, 22, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
      "        22, 21, 21, 20, 21, 21, 22, 21, 20, 21, 21, 20, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 19, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 22,\n",
      "        21, 21, 21, 20, 21, 21, 22, 21, 22, 21, 21, 20, 21, 21])\n",
      "torch.Size([32, 64]) tensor([20, 22, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 19, 21, 21,\n",
      "        21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 19, 20, 21, 20])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 22, 21, 22, 21, 21, 21, 20, 21, 21, 21, 22, 21, 21,\n",
      "        21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 20, 19, 21, 21])\n",
      "torch.Size([32, 64]) tensor([20, 21, 20, 21, 21, 21, 21, 20, 22, 19, 20, 21, 21, 21, 22, 21, 20, 21,\n",
      "        21, 20, 22, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 19])\n",
      "torch.Size([32, 64]) tensor([21, 21, 19, 21, 21, 20, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 22, 21,\n",
      "        21, 19, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 20, 21, 20, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21,\n",
      "        21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 19, 21, 21, 20])\n",
      "torch.Size([32, 64]) tensor([20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20,\n",
      "        20, 21, 22, 19, 21, 21, 21, 21, 21, 22, 22, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([22, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 19, 21, 21, 21, 21,\n",
      "        21, 21, 20, 21, 21, 21, 22, 21, 22, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 20, 21, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
      "        21, 20, 21, 21, 21, 21, 21, 20, 21, 21, 21, 22, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 22, 21, 21, 20, 21, 19, 21, 20, 21, 21, 21, 21, 21, 20, 19, 20,\n",
      "        20, 21, 21, 21, 20, 19, 21, 21, 20, 21, 20, 21, 20, 19])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 20, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21,\n",
      "        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 19, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 21, 21, 21, 22, 21, 21, 22, 20, 20, 21, 21, 22, 21,\n",
      "        21, 21, 21, 21, 21, 22, 21, 21, 21, 21, 21, 21, 20, 21])\n",
      "torch.Size([32, 64]) tensor([21, 22, 21, 21, 21, 20, 19, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21,\n",
      "        21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 22, 21])\n",
      "torch.Size([32, 64]) tensor([20, 21, 21, 20, 21, 21, 20, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21,\n",
      "        20, 20, 21, 21, 21, 21, 22, 21, 21, 21, 18, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 22, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 20,\n",
      "        21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 20, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21,\n",
      "        21, 21, 19, 21, 21, 21, 20, 21, 21, 20, 20, 21, 21, 20])\n",
      "torch.Size([32, 64]) tensor([21, 21, 20, 21, 21, 20, 21, 21, 21, 22, 21, 20, 21, 21, 21, 22, 21, 21,\n",
      "        21, 21, 21, 21, 20, 21, 21, 21, 20, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 21, 20, 19, 20, 21, 21, 21, 21, 20, 21, 21, 20, 21,\n",
      "        20, 20, 20, 21, 21, 21, 21, 20, 20, 21, 21, 21, 20, 21])\n",
      "torch.Size([32, 64]) tensor([20, 21, 21, 20, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
      "        22, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 20, 20, 20, 21, 20, 21, 20, 21, 21, 21, 21, 21, 20, 22,\n",
      "        20, 21, 21, 21, 21, 22, 22, 21, 21, 20, 21, 20, 19, 21])\n",
      "torch.Size([32, 64]) tensor([20, 21, 21, 22, 21, 22, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 20, 21,\n",
      "        21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 21, 20, 20, 21, 20, 21, 21, 22, 21, 22, 21, 21, 21,\n",
      "        20, 20, 21, 21, 21, 21, 21, 21, 19, 21, 20, 20, 20, 21])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) tensor([21, 20, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 20, 21, 21, 20, 20, 21,\n",
      "        21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 22, 20, 21, 21, 19, 21, 20, 21, 21, 21, 21, 21, 22, 21, 21, 21, 21,\n",
      "        21, 21, 21, 21, 21, 22, 22, 21, 21, 21, 20, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 20, 21, 21, 21, 21,\n",
      "        21, 21, 21, 21, 18, 21, 21, 20, 21, 21, 22, 21, 21, 20])\n",
      "torch.Size([32, 64]) tensor([21, 21, 19, 21, 20, 21, 21, 21, 21, 21, 21, 21, 19, 21, 21, 21, 21, 21,\n",
      "        20, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 19, 21, 21, 21, 21, 21, 21, 20, 20, 21, 21, 20, 20,\n",
      "        21, 21, 21, 21, 21, 21, 20, 20, 19, 21, 22, 19, 22, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 20, 21, 21,\n",
      "        21, 21, 20, 21, 21, 21, 21, 20, 21, 21, 20, 21, 20, 20])\n",
      "torch.Size([32, 64]) tensor([21, 21, 19, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 19, 21, 21, 19, 20,\n",
      "        21, 21, 19, 21, 20, 21, 21, 21, 20, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 20, 21, 21, 21, 22, 21, 21, 21, 21, 21, 22, 21, 21, 21, 20, 21,\n",
      "        21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 20, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 19, 20, 21,\n",
      "        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 19, 20, 21, 22, 21, 21, 21, 21, 20, 20, 21, 19, 21,\n",
      "        19, 21, 19, 22, 21, 21, 21, 21, 21, 21, 22, 21, 19, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 21, 21, 21, 20, 20, 20, 21, 21, 19, 21, 20, 21, 20,\n",
      "        21, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 20])\n",
      "torch.Size([32, 64]) tensor([21, 21, 20, 21, 20, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21,\n",
      "        21, 21, 21, 21, 21, 20, 21, 20, 21, 20, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 22, 20, 22,\n",
      "        21, 20, 20, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 20, 20, 19, 22, 21, 20, 22, 21, 21, 21, 21, 21, 21, 21, 22,\n",
      "        21, 21, 22, 21, 20, 20, 21, 20, 20, 21, 21, 19, 21, 22])\n",
      "torch.Size([32, 64]) tensor([21, 22, 20, 21, 21, 21, 19, 21, 21, 21, 20, 22, 21, 21, 21, 20, 21, 21,\n",
      "        20, 19, 20, 21, 20, 21, 21, 20, 21, 20, 21, 21, 20, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 20, 21, 21,\n",
      "        21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 20, 19, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 20, 22, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 22, 21, 21,\n",
      "        21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 20, 21, 21,\n",
      "        21, 21, 21, 21, 21, 20, 21, 19, 22, 21, 21, 21, 21, 20])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 22, 20, 21, 21, 21, 22, 22, 21, 21, 21, 21, 21, 21, 21,\n",
      "        20, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 20])\n",
      "torch.Size([32, 64]) tensor([21, 20, 20, 21, 21, 19, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 20,\n",
      "        22, 20, 21, 22, 21, 19, 20, 20, 21, 21, 21, 21, 21, 22])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
      "        21, 20, 22, 20, 21, 20, 21, 21, 21, 21, 21, 20, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 20, 20, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 20, 19, 21, 21,\n",
      "        21, 22, 21, 20, 21, 21, 21, 20, 21, 21, 20, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([20, 21, 21, 21, 22, 19, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 20, 21,\n",
      "        21, 21, 20, 21, 20, 21, 21, 21, 20, 22, 21, 21, 21, 20])\n",
      "torch.Size([32, 64]) tensor([21, 21, 19, 21, 20, 20, 21, 21, 19, 21, 21, 20, 22, 21, 21, 21, 20, 21,\n",
      "        21, 21, 20, 22, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 21, 20, 21, 20, 21, 21, 21, 19, 21, 22, 21, 21, 21,\n",
      "        21, 20, 21, 20, 21, 21, 21, 21, 21, 20, 20, 19, 21, 20])\n",
      "torch.Size([32, 64]) tensor([20, 21, 21, 21, 20, 22, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
      "        19, 20, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 22, 20, 21, 20, 21,\n",
      "        20, 21, 21, 21, 22, 21, 21, 21, 21, 20, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 20, 21, 21, 21, 20, 21, 21,\n",
      "        21, 21, 20, 21, 22, 19, 21, 20, 21, 20, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 19, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 20, 21, 20, 21,\n",
      "        21, 21, 21, 21, 21, 21, 20, 22, 20, 20, 20, 20, 21, 20])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 20, 22, 21, 21, 21, 20, 21, 20, 20, 21, 21, 21, 21,\n",
      "        21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 21, 21, 20,\n",
      "        22, 22, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 20])\n",
      "torch.Size([32, 64]) tensor([21, 21, 20, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 22, 21, 21,\n",
      "        19, 21, 20, 22, 21, 22, 21, 20, 22, 20, 21, 21, 21, 20])\n",
      "torch.Size([32, 64]) tensor([21, 19, 21, 21, 21, 21, 21, 21, 21, 21, 20, 19, 21, 21, 21, 21, 21, 21,\n",
      "        21, 21, 21, 21, 21, 21, 21, 21, 19, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 20, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21,\n",
      "        21, 19, 19, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 20, 21, 20, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 20, 21, 21, 21,\n",
      "        19, 21, 21, 21, 20, 20, 21, 20, 21, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 20, 21, 19, 21, 20, 22, 20, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21,\n",
      "        21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21, 20])\n",
      "torch.Size([32, 64]) tensor([20, 21, 20, 21, 20, 21, 21, 21, 20, 21, 21, 21, 20, 22, 21, 21, 21, 21,\n",
      "        21, 21, 21, 22, 22, 21, 20, 21, 20, 21, 21, 20, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 20, 20, 21,\n",
      "        21, 20, 20, 21, 20, 21, 21, 22, 21, 20, 22, 21, 21, 22])\n",
      "torch.Size([32, 64]) tensor([22, 20, 21, 21, 21, 21, 21, 21, 20, 22, 21, 21, 21, 21, 21, 20, 21, 21,\n",
      "        21, 19, 20, 21, 21, 21, 20, 21, 21, 20, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 22, 22, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 20, 22, 21, 22,\n",
      "        21, 21, 21, 19, 19, 21, 21, 20, 21, 21, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 20, 21, 21, 20, 21,\n",
      "        21, 21, 20, 21, 21, 19, 21, 21, 21, 19, 21, 22, 22, 20])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 20, 21, 21, 20, 21, 21, 21, 21, 21, 21, 22, 21, 21, 20, 19,\n",
      "        19, 21, 20, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21])\n",
      "torch.Size([32, 64]) tensor([21, 21, 21, 21, 21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21, 21,\n",
      "        21, 21, 21, 19, 21, 21, 19, 21, 21, 21, 22, 21, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (images, tokens) in enumerate(dataloader):\n",
    "    print(tokens.shape, tokens.argmax(dim=-1))\n",
    "    \n",
    "    if batch_idx>=100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "934c502f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21, 21, 21, 21, 21, 20, 21, 21, 21, 21, 20, 21, 21, 21, 21, 21, 21, 21,\n",
       "        21, 21, 21, 21, 21, 19, 22, 21, 21, 21, 21, 21, 20, 19],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition.argmax(dim=-1).to(torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15678964",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('test_data.npy', something.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b455604",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('test_data_text.npy', condition.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f15f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = torch.from_numpy(np.random.randint(32,50,[32,64]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d6c3fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8f51a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_encoder = text_encoder()\n",
    "txt_encoder(text).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5affd82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
